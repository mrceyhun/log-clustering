#!/bin/bash
# Author: Valentin Kuznetsov <vkuznet AT gmail [DOT] com>
# A wrapper script to submit spark job with python script.

# Kerberos
keytab=/etc/secrets/keytab
if [ -f $keytab ]; then
    principal=$(klist -k "$keytab" | tail -1 | awk '{print $2}')
    echo "principal=$principal"
    kinit "$principal" -k -t "$keytab"
    if [ $? == 1 ]; then
        echo "Unable to perform kinit"
        exit 1
    fi
    klist -k "$keytab"
fi

# test arguments
if [ "$#" -eq 0 ]; then
    echo "Usage: run_spark <pyspark_script> <port1> <port2> <port3> <options>"
    echo "Usage: Ports are spark.driver, spark.blockManager, spark.ui which will be of K8s host ports!"
    exit 1
fi
cmsspark=$1
if [ "$2" == "-h" ] || [ "$2" == "--help" ] || [ "$2" == "-help" ]; then
    python3 "$cmsspark" --help
    exit 0
fi
p1=$2
p2=$3
p3=$4
shift 4
args=("$@")

conf=(
    --master yarn
    --conf spark.security.credentials.hive.enabled=false --conf spark.hadoop.dfs.client.socket-timeout=120000
    --conf spark.ui.showConsoleProgress=false --executor-memory=5g
    --packages org.apache.spark:spark-avro_2.12:3.3.1
    --conf spark.authenticate.secret=cmsspark
    --conf spark.driver.port="$p1" --conf spark.blockManager.port="$p2" --conf spark.ui.port="$p3"
)
# Set Java Home
if [ -n "$JAVA_HOME" ]; then
    if [ -e "/usr/lib/jvm/java-1.8.0" ]; then
        export JAVA_HOME="/usr/lib/jvm/java-1.8.0"
    elif ! (java -XX:+PrintFlagsFinal -version 2>/dev/null | grep -E -q 'UseAES\s*=\s*true'); then
        util4loge "this script requires a java version with AES enabled"
        exit 1
    fi
fi

echo "PYTHONPATH: $PYTHONPATH"
echo cmsspark: "$cmsspark" args: "${args[@]}"
echo YARN execution: "${conf[@]}"

# Setup hadoop and spark
export PYSPARK_DRIVER_PYTHON=/usr/bin/python
export HADOOP_CONF_DIR=/etc/hadoop/conf
export PATH="${PATH}:${WDIR}:${WDIR}/log-clustering:${WDIR}/log-clustering/workflow:/usr/hdp/hadoop/bin/hadoop:/usr/hdp/spark3/bin"
export PYTHONPATH="${PYTHONPATH}:${WDIR}"
export PYSPARK_PYTHON=/cvmfs/sft.cern.ch/lcg/releases/Python/3.9.6-b0f98/x86_64-centos7-gcc8-opt/bin/python3

hadoop-set-default-conf.sh analytix 'hadoop spark' 3.2
source hadoop-setconf.sh analytix 3.2 spark3

sed -i 's/rootLogger.level = info/rootLogger.level = warn/g' "$SPARK_CONF_DIR"/log4j2.properties

# Run
spark-submit "${conf[@]}" "$cmsspark" "${args[@]}"
